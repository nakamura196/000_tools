{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNdlZwGUD1r06H/i+4DUZs6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nakamura196/000_tools/blob/main/LlamaIndex%2BGPT4%2Bgradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LlamaIndex+GPT4+gradio\n",
        "\n",
        "以下の記事を参考にしています。\n",
        "\n",
        "https://qiita.com/DeepTama/items/1a44ddf6325c2b2cd030\n",
        "\n",
        "2024年4月20日時点のライブラリで動作するように修正しています。\n",
        "\n",
        "以下のデータを使用しています。\n",
        "\n",
        "TEIを用いた『渋沢栄一伝記資料』テキストデータの再構築と活用\n",
        "\n",
        "https://github.com/shibusawa-dlab/lab1"
      ],
      "metadata": {
        "id": "DusolbUJSc3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 環境変数の準備\n",
        "\n",
        "以下を参考に、`OPENAI_API_KEY`を設定します。\n",
        "\n",
        "https://note.com/npaka/n/n79bb63e17685"
      ],
      "metadata": {
        "id": "IKj1T4LJaRwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "hVgP68fHYAbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ライブラリのインストール"
      ],
      "metadata": {
        "id": "6mZxL7MiSo_i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wqHlkFIX6Sp"
      },
      "outputs": [],
      "source": [
        "# LlmaIndexパッケージのインストール (今回は0.8.0で検証)\n",
        "!pip install llama-index\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ログレベルの設定\n",
        "import logging\n",
        "import sys\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.readers.file.docs.base import DocxReader\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.core import GPTVectorStoreIndex, ServiceContext, SimpleDirectoryReader\n",
        "from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler\n",
        "from llama_index.core.prompts.prompts import QuestionAnswerPrompt\n",
        "import glob\n",
        "from bs4 import BeautifulSoup\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "CrUZxzOUX679"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open AIのGPT4をLLMとして指定しServiceContextに設定する\n",
        "llm = OpenAI(model='gpt-4', temperature=0.5, max_tokens=1024)\n",
        "llama_debug_handler = LlamaDebugHandler()\n",
        "callback_manager = CallbackManager([llama_debug_handler])\n",
        "service_context = ServiceContext.from_defaults(llm=llm, callback_manager=callback_manager) # , callback_manager=callback_manager"
      ],
      "metadata": {
        "id": "wWwLxklrYJGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## テキスト"
      ],
      "metadata": {
        "id": "DAbPIziMoMHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 場所は任意ですが、今回は `sample_data` の下に、 `data`ディレクトを作成\n",
        "%cd sample_data\n",
        "%mkdir data"
      ],
      "metadata": {
        "id": "8HZn5k6oQ3_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テキストデータのダウンロード\n",
        "!wget https://raw.githubusercontent.com/shibusawa-dlab/lab1/master/tei/DKB01.xml\n",
        "!wget https://raw.githubusercontent.com/shibusawa-dlab/lab1/master/tei/DKB02.xml"
      ],
      "metadata": {
        "id": "auwCn43toNwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/sample_data/data\n",
        "!mkdir /content/sample_data/data\n",
        "\n",
        "files = glob.glob(\"*.xml\")\n",
        "\n",
        "# 各ファイルをループ処理\n",
        "for file_name in files:\n",
        "    # ファイルを開いて読み込む\n",
        "    with open(file_name, 'r', encoding='utf-8') as file:\n",
        "        # BeautifulSoupオブジェクトを作成\n",
        "        soup = BeautifulSoup(file, 'lxml-xml')  # XMLファイル用のパーサーを指定\n",
        "\n",
        "        entries = soup.find_all(type=\"diary-entry\")\n",
        "\n",
        "        for entry in entries:\n",
        "          id = entry[\"xml:id\"]\n",
        "\n",
        "          output_path = f\"/content/sample_data/data/{id}.txt\"\n",
        "\n",
        "          with open(output_path, 'w', encoding='utf-8') as output_file:\n",
        "              text_only = entry.get_text()\n",
        "              text_only = ' '.join(text_only.split())\n",
        "              output_file.write(text_only)  # Convert the BeautifulSoup tag object to string\n"
      ],
      "metadata": {
        "id": "3DvUavOXooVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ドキュメントの読み込み\n",
        "documents = SimpleDirectoryReader(\n",
        "    input_dir=\"/content/sample_data/data\"\n",
        ").load_data()"
      ],
      "metadata": {
        "id": "ul0TohtXa7DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Document -> Knowledge Base生成を行うステップ\n",
        "index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)"
      ],
      "metadata": {
        "id": "WbTZK0QyeCZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 保存（参考）"
      ],
      "metadata": {
        "id": "iGPfui6GuEPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "storage_context = index.storage_context\n",
        "storage_context.persist(persist_dir=\"./storage_context\")"
      ],
      "metadata": {
        "id": "Xdu7k2Fjm1sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r storage_context.zip \"./storage_context\""
      ],
      "metadata": {
        "id": "Gw2driFKm9KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 実行"
      ],
      "metadata": {
        "id": "Nk4LftWtuG4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# QAテンプレートの準備\n",
        "qa_template = QuestionAnswerPrompt(\"\"\"<s>[INST] <<SYS>>\n",
        "質問に答えてください。\n",
        "<</SYS>>\n",
        "== 以下にコンテキスト情報を提供します。\n",
        "{context_str}\n",
        "== 質問\n",
        "{query_str}\n",
        "\n",
        " [/INST]\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "2YznZK21e6TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_top_k = 30 # 50 # 10 # 20 # 3"
      ],
      "metadata": {
        "id": "xHMDmiEJf7KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLMへの問い合わせ\n",
        "# この時indexを参照し、問い合わせに近い情報（チャンク）を取得し、それをプロンプトに組み込む\n",
        "# 幾つのチャンクを組み込むのかを `similarity_top_k` で指定する\n",
        "query_engine = index.as_query_engine(\n",
        "    similarity_top_k=similarity_top_k,\n",
        "    text_qa_template=qa_template,\n",
        ")"
      ],
      "metadata": {
        "id": "eLeazypGe4Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_response(response):\n",
        "    for node in response.source_nodes:\n",
        "        if node.node.extra_info is not None:\n",
        "            if \"file_name\" in node.node.extra_info:\n",
        "                print(node.node.extra_info[\"file_name\"])\n",
        "        print(node.node.node_info)\n",
        "        if node.score is not None:\n",
        "            print(node.score)\n",
        "        print(\"-----------------------------------------------------------------------------\")\n",
        "        print(node.node.text)\n",
        "\n",
        "        print(\"============================================================================================================\")"
      ],
      "metadata": {
        "id": "oF_kzhleRY02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"あなたは何時に起床することが多いですか？\"\n",
        "\n",
        "response = query_engine.query(query)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "tdZl3hzrfKFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "query = \"よく行く場所はどこですか？\"\n",
        "\n",
        "response = query_engine.query(query)\n",
        "print(response)\n",
        "'''"
      ],
      "metadata": {
        "id": "fPeB7FeMfVYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "query = \"誰と会うことが多いですか？\"\n",
        "\n",
        "response = query_engine.query(query)\n",
        "print(response)\n",
        "'''"
      ],
      "metadata": {
        "id": "9O7oMC-Sv7vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"京釜鉄道会社事務所はどこにありますか？\"\n",
        "response = query_engine.query(query)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "1chf0SOhlzAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_response(response)"
      ],
      "metadata": {
        "id": "uk6tkphNjDpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio"
      ],
      "metadata": {
        "id": "AQtEwfPFSZcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_text(history, text):\n",
        "    history = history + [(text, None)]\n",
        "    return history, gr.Textbox(value=\"\", interactive=False)\n",
        "\n",
        "def bot(history):\n",
        "    query = history[-1][0]\n",
        "    response = str(query_engine.query(query))\n",
        "    history[-1][1] = \"\"\n",
        "    for character in response:\n",
        "        history[-1][1] += character\n",
        "        yield history\n",
        "\n",
        "# show_error=True\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    with gr.Row():\n",
        "        txt = gr.Textbox(\n",
        "            scale=4,\n",
        "            show_label = False,\n",
        "            container = False\n",
        "        )\n",
        "    clear = gr.Button(\"Clear\")\n",
        "\n",
        "    txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue = False).then(bot, chatbot, chatbot)\n",
        "    txt_msg.then(lambda: gr.Textbox(interactive = True), None, [txt], queue = False)\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "demo.queue()\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "EaJ-NPAmwybf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}